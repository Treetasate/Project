import streamlit as st
import numpy as np
import pandas as pd
import tensorflow as tf
from pythainlp.corpus import thai_stopwords
from pythainlp.tokenize import word_tokenize
from tensorflow.keras.preprocessing.text import Tokenizer
import tensorflow.keras as keras
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression, LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.model_selection import train_test_split


# Load data
url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQO5tgsRIpeMbYT0B_b6zTeSZmHkFl9FjPrvCsczYk7-WMgAVj52JpX4Gl72WHp5gLS9hH_g2BG88Ko/pub?gid=2062330787&single=true&output=csv'
df = pd.read_csv(url)

# Thai stopwords
thai_stopwords_list = thai_stopwords()

# Text preprocessing function
def text_process(text):
    if not isinstance(text, str):
        return ""
    tokens = word_tokenize(text)
    final = [word for word in tokens if word.lower() not in thai_stopwords_list]
    return " ".join(final)

# Preprocess the dataframe
df['text_tokens'] = df['‡∏ö‡∏ó‡∏Ñ‡∏±‡∏î‡∏¢‡πà‡∏≠'].apply(text_process)

def appLSTM():
    # Prepare data for training
    texts = df['text_tokens']
    labels = df['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ']
    label_encoder = LabelEncoder()
    labels = label_encoder.fit_transform(labels)

    max_words = 10000
    max_len = 100
    embedding_dim = 100
    lstm_units = 64
    num_classes = len(set(labels))

    tokenizer = Tokenizer(num_words=max_words)
    tokenizer.fit_on_texts(texts)
    sequences = tokenizer.texts_to_sequences(texts)
    x = pad_sequences(sequences, maxlen=max_len)
    y = keras.utils.to_categorical(labels, num_classes)

    # Build and compile the model
    modellstm = Sequential()
    modellstm.add(Embedding(max_words, embedding_dim))
    modellstm.add(LSTM(lstm_units))
    modellstm.add(Dense(num_classes, activation='softmax'))
    modellstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    # Train the model
    modellstm.fit(x, y, batch_size=32, epochs=10)

    # Prediction function
    def predict_class(input_text):
        processed_text = text_process(input_text)
        sequences_new = tokenizer.texts_to_sequences([processed_text])
        sequences_padded_new = pad_sequences(sequences_new, maxlen=max_len)
        y_pred_classes_new = modellstm.predict(sequences_padded_new).argmax(axis=1)
        return label_encoder.inverse_transform(y_pred_classes_new)[0]

    # Streamlit UI
    st.title("üê±‚Äçüëì Prediction by LSTM üê±‚Äçüèç")
    input_text = st.text_area("‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà","",height=200)
    if st.button("‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢"):
        if not input_text:
            st.write("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")
        else:
            prediction = predict_class(input_text)
            st.write("‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:", prediction)

def appRandom():
    XRd = df['text_tokens']
    yRd = df['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ']

    X_train, X_test, y_train, y_test = train_test_split(XRd, yRd, test_size=0.3, random_state=42)

    tfidf_vectorizer = TfidfVectorizer()
    X_train_vectorized = tfidf_vectorizer.fit_transform(X_train)
    X_test_vectorized = tfidf_vectorizer.transform(X_test)

    random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
    random_forest_classifier.fit(X_train_vectorized, y_train)

    st.title("üéÑ Prediction by Random Forest üå≥")

    # ‡∏£‡∏ß‡∏°‡∏ä‡πà‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    input_text = st.text_area("‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà", "",height=200)
    if st.button("‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢"):
        if not input_text:
            st.write("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")
        else:
            # ‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡πÅ‡∏•‡πâ‡∏ß
            # Vectorize the input text using the same TfidfVectorizer
            X_new = [text_process(input_text)]
            X_new_vectorized = tfidf_vectorizer.transform(X_new)
            
            # Predict using the trained Random Forest model
            y_new_pred = random_forest_classifier.predict(X_new_vectorized)

            # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            st.write("‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:", y_new_pred[0])

def appNavivebayes():
    X = df['text_tokens']
    y = df['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # Vectorization
    tfidf_vectorizer = TfidfVectorizer()
    X_train_vectorized = tfidf_vectorizer.fit_transform(X_train)
    X_test_vectorized = tfidf_vectorizer.transform(X_test)

    # Training Naive Bayes Model
    naive_bayes_classifier = MultinomialNB()
    naive_bayes_classifier.fit(X_train_vectorized, y_train)

    # Streamlit UI
    st.title("üîÆ Prediction by Naivebayes üîÆ")
    input_text = st.text_area("‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà", "",height=200)
    if st.button("‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢"):
        if not input_text:
            st.write("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")
        else:
            processed_text = text_process(input_text)
            X_new = [processed_text]
            X_new_vectorized = tfidf_vectorizer.transform(X_new)
            y_new_pred = naive_bayes_classifier.predict(X_new_vectorized)
            st.write("‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:", y_new_pred[0])

def appLogisticRegression():
                # ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                def prepare_data(df):
                    thai_stopwords_list = thai_stopwords()

                    def text_process(text):
                        if not isinstance(text, str):
                            return ""
                        tokens = word_tokenize(text)
                        final = [word for word in tokens if word.lower() not in thai_stopwords_list]
                        return " ".join(final)

                    df['text_tokens'] = df['‡∏ö‡∏ó‡∏Ñ‡∏±‡∏î‡∏¢‡πà‡∏≠'].apply(text_process)

                    Xlr = df[['text_tokens']]
                    ylr = df['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ']

                    X_train, X_test, y_train, y_test = train_test_split(Xlr, ylr, test_size=0.3)

                    cvec = CountVectorizer(analyzer=lambda x:x.split(' '))
                    cvec.fit_transform(X_train['text_tokens'].values.astype('U'))

                    return cvec, X_train, X_test, y_train, y_test

                cvec, X_train, X_test, y_train, y_test = prepare_data(df)

                # ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
                lr = LogisticRegression()
                lr.fit(cvec.transform(X_train['text_tokens'].values.astype('U')), y_train)

                # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
                def predict_class(input_text):
                    processed_input = cvec.transform([input_text])
                    prediction = lr.predict(processed_input)
                    return prediction[0]

                # ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
                st.title("üöê Prediction by LogisticRegression")
                input_text = st.text_area("‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà", "", height=200)
                if st.button("‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢"):
                    if not input_text:
                        st.write("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")
                    else:
                        prediction = predict_class(input_text)
                        st.write("‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:", prediction)

def appCNN():
    # Train and return a model and vectorizer
    def train_model(df):
        X_train, X_test, y_train, y_test = train_test_split(df['text_tokens'], df['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ'], test_size=0.3)
        cvec = CountVectorizer(analyzer=lambda x: x.split(' '))
        cvec.fit(X_train)
        lr = LogisticRegression()
        lr.fit(cvec.transform(X_train), y_train)
        return lr, cvec

    # Function to predict the class of a new input
    def predict_class(input_text, model, vectorizer):
        processed_input = text_process(input_text)
        new_data_bow = vectorizer.transform([processed_input])
        return model.predict(new_data_bow)

    # Streamlit UI
    st.title(" Prediction by CNN üñ•")
    input_text = st.text_area("‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà", "", height=200)

    # Train the model and prepare the vectorizer
    model, vectorizer = train_model(df)

    if st.button("‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢"):
        if not input_text:
            st.write("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")
        else:
            prediction = predict_class(input_text, model, vectorizer)
            st.write("‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:", prediction)

st.title("üîÆ Predict machine üîÆ")

# ‡πÉ‡∏ä‡πâ selectbox ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤
page = st.selectbox('‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ : ', ['LSTM', 'RandomForest', 'Navivebayes', 'LogisticRegression', 'CNN'])

# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
if page == 'LSTM':
    appLSTM()
elif page == 'RandomForest':
    appRandom()
elif page == 'Navivebayes':
    appNavivebayes()
elif page == 'LogisticRegression':
    appLogisticRegression()
elif page == 'CNN':
    appCNN()